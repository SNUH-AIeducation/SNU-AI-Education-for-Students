{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Medical Record Analysis and Discharge Summary Generation\n",
    "\n",
    "This tutorial demonstrates how to generate discharge summaries by analyzing and summarizing initial admission notes and progress notes during hospitalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import Required Libraries and Load Data\n",
    "\n",
    "First, we'll import the necessary libraries and load our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리눅스 패키지 업데이트 및 cairo 설치\n",
    "!apt update -y\n",
    "!apt install -y libcairo2-dev pkg-config\n",
    "!pip install pycairo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set cache directory for Hugging Face datasets and Transformers library\n",
    "os.environ['HF_DATASETS_CACHE'] = '/home/jovyan/work/model/mllm_demo/transformers_cache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = '/home/jovyan/work/model/mllm_demo/transformers_cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'torch.version' from '/usr/local/lib/python3.11/dist-packages/torch/version.py'>\n",
      "12.4\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.version)\n",
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate numpy pandas rouge transformers typing openpyxl accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-30 09:48:31.254371: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-30 09:48:31.272930: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-30 09:48:31.295964: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-30 09:48:31.302990: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-30 09:48:31.320223: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import torch\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rouge import Rouge\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Tuple, Any\n",
    "from transformers import MllamaForConditionalGeneration, AutoProcessor\n",
    "\n",
    "# Load Data from Excel File\n",
    "file_path = 'combined_patient_records_summary_demo.xlsx'\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define Data Processing Functions\n",
    "\n",
    "We'll define several functions to process and structure our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMN_NAMES = {\n",
    "    'item': '서식항목명',     # item name - Defines the type or category of the medical form element\n",
    "    'content': '서식내용',    # content - Contains the actual medical information or notes\n",
    "    'time': '서식작성일',     # creation date - When the medical record was created\n",
    "    'category': '서식구분명',  # category name - Classifies the type of medical record\n",
    "    'patient_id': '연구별 환자 ID'  # Patient ID for research - Unique identifier for each patient in the study\n",
    "}\n",
    "\n",
    "NOTE_TYPES = {\n",
    "    'Admission_Note': '입원초진',        # Admission Note - First detailed examination upon hospital admission\n",
    "    'Discharge_Summary': '퇴원기록',      # Discharge Summary - Final summary of the patient's hospital stay\n",
    "    'Progress_Notes' : '입원경과'\n",
    "}\n",
    "\n",
    "def get_medical_note_sections() -> List[str]:\n",
    "    \"\"\"\n",
    "    Returns the standard order of medical note sections.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: Ordered list of standard medical note section names\n",
    "    \"\"\"\n",
    "    return [\n",
    "        \"Present Illness\", \"Past History\", \"Social History\", \"Family History\", \"*History\",\n",
    "        \"Review Of System\", \"Physical Examination\", \"소견\", \"Assessment\", \"Plan\"\n",
    "    ]\n",
    "\n",
    "def get_section_priority(section_name: str) -> int:\n",
    "    \"\"\"\n",
    "    Determines the priority order of medical note sections.\n",
    "    \n",
    "    Args:\n",
    "        section_name: Name of the medical note section\n",
    "        \n",
    "    Returns:\n",
    "        int: Priority index of the section (lower number means higher priority)\n",
    "    \"\"\"\n",
    "    section_order = get_medical_note_sections()\n",
    "    \n",
    "    for index, pattern in enumerate(section_order):\n",
    "        if pattern == \"*History\" and \"History\" in section_name and section_name not in section_order:\n",
    "            return index\n",
    "        if pattern in section_name:\n",
    "            return index\n",
    "    return len(section_order)\n",
    "\n",
    "def convert_form_key_direction(form_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Converts arrow direction in form item names from '<-' to '->'.\n",
    "    \n",
    "    Args:\n",
    "        form_key: Original form key with '<-' direction\n",
    "        \n",
    "    Returns:\n",
    "        str: Converted form key with '->' direction\n",
    "    \"\"\"\n",
    "    return ' -> '.join(reversed(form_key.split(' <- ')))\n",
    "\n",
    "def parse_medical_note(df: Any) -> Tuple[Dict[str, str], Any]:\n",
    "    \"\"\"\n",
    "    Extracts and organizes medical note content from DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing medical note data\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[Dict[str, str], Any]: A tuple containing:\n",
    "            - Dictionary of sorted medical note content\n",
    "            - Timestamp of the note\n",
    "    \"\"\"\n",
    "    medical_note_content = {}\n",
    "    note_timestamp = None\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        form_item = convert_form_key_direction(row[COLUMN_NAMES['item']])\n",
    "        content = row[COLUMN_NAMES['content']]\n",
    "        medical_note_content[form_item] = content\n",
    "\n",
    "        if note_timestamp is None:\n",
    "            note_timestamp = row[COLUMN_NAMES['time']]\n",
    "\n",
    "    return dict(sorted(medical_note_content.items(), key=lambda x: get_section_priority(x[0]))), note_timestamp\n",
    "\n",
    "def format_discharge_note(note_content: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Formats discharge note content with proper indentation and structure.\n",
    "    \n",
    "    Args:\n",
    "        note_content: Dictionary containing discharge note content\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted discharge note with proper indentation\n",
    "    \"\"\"\n",
    "    formatted_lines = []\n",
    "    for section_key, content in note_content.items():\n",
    "        section_hierarchy = section_key.split(' -> ')\n",
    "        for level, section in enumerate(section_hierarchy):\n",
    "            formatted_lines.append('    ' * level + section)\n",
    "        \n",
    "        cleaned_content = content.replace('_x000D_\\n', '\\n').replace('*x000D*\\n', '\\n')\n",
    "        content_lines = cleaned_content.split('\\n')\n",
    "        indented_content = '\\n'.join('    ' * len(section_hierarchy) + line.strip() \n",
    "                                    for line in content_lines if line.strip())\n",
    "        formatted_lines.append(indented_content)\n",
    "        formatted_lines.append('')\n",
    "    \n",
    "    return '\\n'.join(formatted_lines)\n",
    "\n",
    "def format_note_date(timestamp: Any) -> str:\n",
    "    \"\"\"\n",
    "    Formats medical note timestamp into standardized date string.\n",
    "    \n",
    "    Args:\n",
    "        timestamp: Date timestamp in various possible formats\n",
    "        \n",
    "    Returns:\n",
    "        str: Standardized date string in 'YYYY-MM-DD' format\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_obj = datetime.strptime(str(timestamp), '%Y-%m-%d')\n",
    "        return date_obj.strftime('%Y-%m-%d')\n",
    "    except ValueError:\n",
    "        return str(timestamp)\n",
    "\n",
    "def generate_formatted_notes(df: Any, note_type: str, is_discharge_note: bool = False) -> str:\n",
    "    \"\"\"\n",
    "    Generates formatted medical notes from DataFrame for specified note type.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing medical records\n",
    "        note_type: Type of medical note ('Admission_Note' or 'Discharge_Summary')\n",
    "        is_discharge_note: Boolean flag for discharge note formatting\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted medical notes as a single string\n",
    "    \"\"\"\n",
    "    formatted_notes = []\n",
    "    category = NOTE_TYPES[note_type]\n",
    "    \n",
    "    category_df = df[df[COLUMN_NAMES['category']] == category]\n",
    "    if not category_df.empty:\n",
    "        note_content, timestamp = parse_medical_note(category_df)\n",
    "        \n",
    "        if is_discharge_note:\n",
    "            discharge_patterns = r'입원사유.*병력요약|입원경과'  # Reason for admission.*History summary|progress notes\n",
    "            note_content = {k: v for k, v in note_content.items() \n",
    "                          if re.search(discharge_patterns, k)}\n",
    "            if note_content:\n",
    "                formatted_text = format_discharge_note(note_content)\n",
    "                formatted_notes.extend([\n",
    "                    f\">>>{category}<<<\",\n",
    "                    format_note_date(timestamp),\n",
    "                    formatted_text\n",
    "                ])\n",
    "        else:\n",
    "            formatted_text = json.dumps(note_content, ensure_ascii=False, indent=4)\n",
    "            formatted_notes.extend([\n",
    "                f\">>>{category}<<<\",\n",
    "                format_note_date(timestamp),\n",
    "                formatted_text\n",
    "            ])\n",
    "\n",
    "    return \"\\n\".join(formatted_notes)\n",
    "\n",
    "def process_patient_records(df: Any) -> Dict[Any, Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Processes and organizes medical records for multiple patients.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame containing all patient medical records\n",
    "        \n",
    "    Returns:\n",
    "        Dict[Any, Dict[str, str]]: Dictionary containing processed records for each patient:\n",
    "            - Key: Patient ID\n",
    "            - Value: Dictionary with 'Admission_Note' and 'Discharge_Summary' keys\n",
    "    \"\"\"\n",
    "    patient_records = {}\n",
    "    \n",
    "    for patient_id in df[COLUMN_NAMES['patient_id']].unique():\n",
    "        patient_df = df[df[COLUMN_NAMES['patient_id']] == patient_id]\n",
    "        \n",
    "        patient_records[patient_id] = {\n",
    "            'Admission_Note': generate_formatted_notes(patient_df, 'Admission_Note'),\n",
    "            'Discharge_Summary': generate_formatted_notes(patient_df, 'Discharge_Summary', \n",
    "                                                       is_discharge_note=True),\n",
    "            'Progress_Notes' : generate_formatted_notes(patient_df, 'Progress_Notes')\n",
    "        }\n",
    "    \n",
    "    return patient_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check Patient Record in Korean\n",
    "patient_records = process_patient_records(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Load Model\n",
    "\n",
    "Load the Llama model for analyzing and summarizing medical records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model weights are not tied. Please use the `tie_weights` method before using the `infer_auto_device` function.\n",
      "Loading checkpoint shards: 100%|██████████| 5/5 [00:06<00:00,  1.31s/it]\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/home/jovyan/work/model/mllm_demo/transformers_cache/models--meta-llama--Llama-3.2-11B-Vision-Instruct/.no_exist/cee5b78e6faed15d5f2e6d8a654fd5b247c0d5ca/processor_config.json'\n",
      "Could not cache non-existence of file. Will ignore error and continue. Error: [Errno 30] Read-only file system: '/home/jovyan/work/model/mllm_demo/transformers_cache/models--meta-llama--Llama-3.2-11B-Vision-Instruct/.no_exist/cee5b78e6faed15d5f2e6d8a654fd5b247c0d5ca/processor_config.json'\n"
     ]
    }
   ],
   "source": [
    "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
    "token = \"\"\n",
    "\n",
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    temperature = 0.1,\n",
    "    token = token\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-1. Define Section Extraction Functions\n",
    "\n",
    "Define functions to extract specific sections from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_discharge_summary_sections(discharge_text: str) -> str:\n",
    "    \"\"\"Extracts specific sections from patient's discharge summary.\"\"\"\n",
    "    target_sections = ['입원경과', '입원사유 및 병력요약']  # 'Hospital Course', 'Reason for Admission and Summary of Medical History'\n",
    "    text_lines = discharge_text.split('\\n')\n",
    "    formatted_sections = []\n",
    "    section_start_indices = []\n",
    "\n",
    "    for line_index in reversed(range(len(text_lines))):\n",
    "        if text_lines[line_index].strip() in target_sections:\n",
    "            section_start_indices.append(line_index)\n",
    "            if len(section_start_indices) == len(target_sections):\n",
    "                break\n",
    "\n",
    "    if len(section_start_indices) < len(target_sections):\n",
    "        return discharge_text.strip()\n",
    "\n",
    "    current_line_index = section_start_indices[1]\n",
    "\n",
    "    while current_line_index < len(text_lines):\n",
    "        current_line = text_lines[current_line_index].rstrip()\n",
    "        \n",
    "        if current_line.strip() in target_sections:\n",
    "            formatted_sections.append(current_line)\n",
    "            current_line_index += 1\n",
    "            \n",
    "            while current_line_index < len(text_lines):\n",
    "                next_line = text_lines[current_line_index].rstrip()\n",
    "                \n",
    "                if next_line.startswith(('    ', '\\t')):\n",
    "                    formatted_sections.append(next_line)\n",
    "                    current_line_index += 1\n",
    "                elif next_line.strip() in target_sections:\n",
    "                    break\n",
    "                else:\n",
    "                    current_line_index += 1\n",
    "                    \n",
    "            formatted_sections.append(\"\")\n",
    "        else:\n",
    "            current_line_index += 1\n",
    "\n",
    "    return '\\n'.join(formatted_sections).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-2. Generate Medical Record Summaries Using the Model\n",
    "\n",
    "### Summarize each patient's medical records using the loaded model.\n",
    "\n",
    "This example shows a medical record structure where both input (Initial Admission Note, Progress Note) and output (Discharge Summary) were translated from Korean to English for better understanding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Patient #0 =======\n",
      "입원경과\n",
      "    2023-03-03 Adm\n",
      "    2023-05-09 Op\n",
      "\n",
      "입원사유 및 병력요약\n",
      "    Description\n",
      "        상환 양손 저린감으로 내원하여 CTS, B/L(Bland 1/3)에 대해 외래 추시중이던 분으로, 보존적 치료로 나아지지 않는 증상으로 금번 CTR, Lt.위해 내원.\n",
      "Processing Patient #1 =======\n",
      "입원경과\n",
      "    2023-03-15 Adm\n",
      "    2023-03-15 Op\n",
      "\n",
      "입원사유 및 병력요약\n",
      "    Description\n",
      "        상환 양손 저림증상으로 내원하여 CTS, B/L에 대해 외래 추시중이던 분으로, 보존적 치료로 호전 보이지 않아 금번 CTR, Rt + A1 pulley release, 3th finger, Rt. 위해 내원.\n",
      "Processing Patient #2 =======\n",
      "입원경과\n",
      "    2023-03-26 Adm\n",
      "    2023-05-11 Op\n",
      "\n",
      "입원사유 및 병력요약\n",
      "    Description\n",
      "        상환 2년전부터 시작된 Lt. 2nd finger의 triggering을 주소로 외래추시중이던 분으로, 보존적 치료에 반응하지 않아 금번 A1 pulley release, 2nd finger, Lt. 위해 내원.\n",
      "Processing Patient #3 =======\n",
      "입원경과\n",
      "    2023-04-07 Adm\n",
      "    2023-05-12 Op\n",
      "\n",
      "입원사유 및 병력요약\n",
      "    Description\n",
      "        # DDLT recipient\n",
      "Processing Patient #4 =======\n",
      "입원경과\n",
      "    2023-04-27 Adm\n",
      "    2023-03 Op\n",
      "\n",
      "입원사유 및 병력요약\n",
      "    Description\n",
      "        상환 3번쨰 손가락의 triggering으로 외래 방문하여, A1 pulley release 수술 위해 입원함.\n",
      "Translating Summary #0 =======\n",
      "Admission and Discharge Information\n",
      "    Admission Date: 2023-03-03\n",
      "    Discharge Date: 2023-05-09\n",
      "\n",
      "Reason for Hospitalization and Medical History Summary\n",
      "    Description\n",
      "        Admitted with a complaint of bilateral hand numbness and was referred by an outpatient doctor who had been following up on CTS (Carpal Tunnel Syndrome) and B/L (Bilateral) (Bland 1/3) for conservative treatment, but symptoms did not improve, and was admitted for CTR (Carpal Tunnel Release) and Lt. (Left) surgery.\n",
      "Translating Summary #1 =======\n",
      "Admission and Operation History\n",
      "    2023-03-15 Admitted\n",
      "    2023-03-15 Operated\n",
      "\n",
      "Reason for Hospitalization and Past Medical Summary\n",
      "    Description\n",
      "        Admitted with symptoms of bilateral hand numbness and visited for follow-up for CTS (Carpal Tunnel Syndrome) and B/L (bilateral). As conservative treatment did not show improvement, visited for this admission for CTR (Carpal Tunnel Release) and Rt + A1 pulley release, 3rd finger, Rt.\n",
      "Translating Summary #2 =======\n",
      "Admission and Discharge Information\n",
      "    Admission Date: 2023-03-26\n",
      "    Discharge Date: 2023-05-11\n",
      "\n",
      "Reason for Hospitalization and Medical History Summary\n",
      "    Description\n",
      "        The patient, who had been followed up as an outpatient since 2 years ago due to triggering of Lt. 2nd finger, visited the hospital this time for A1 pulley release and Lt. 2nd finger surgery as conservative treatment did not respond.\n",
      "Translating Summary #3 =======\n",
      "Admission and Hospital Course\n",
      "    2023-04-07 Admitted\n",
      "    2023-05-12 Discharged\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        # Living Donor Liver Transplant recipient\n",
      "Translating Summary #4 =======\n",
      "Admission and Hospital Course\n",
      "    2023-04-27 Admission\n",
      "    2023-03 Operation\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        Admitted for A1 pulley release surgery due to triggering of the 3rd finger.\n"
     ]
    }
   ],
   "source": [
    "def create_llm_prompt(admission_notes: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Creates a prompt for the LLM to generate discharge summary.\n",
    "    \n",
    "    Args:\n",
    "        admission_notes: Cleaned admission and progress notes\n",
    "    \n",
    "    Returns:\n",
    "        List of message dictionaries for the LLM\n",
    "    \"\"\"\n",
    "    system_prompt = \"\"\"\n",
    "    You are an attending physician (specialist) collaborating with a resident doctor (house staff) to write a discharge summary based on patient records. Your goal is to provide accurate and complete information without adding any assumptions or interpretations not present in the original data.\n",
    "    \"\"\"\n",
    "    \n",
    "    user_prompt = f\"\"\"\n",
    "    Using the patient data provided below, focus on extracting and presenting key information for '입원경과' (Hospital Course) and '입원사유 및 병력요약' (Reason for Admission and Summary of Medical History). Use the information from the '입원초진' (Admission Initial Assessment) and '입원경과' (Hospital Course) sections.\n",
    "    \n",
    "    Patient Data: {admission_notes}\n",
    "    \n",
    "    Follow the output format below:\n",
    "    입원경과\n",
    "        [Admission Date] Adm\n",
    "        [Operation Date] Op\n",
    "\n",
    "    입원사유 및 병력요약\n",
    "        Description\n",
    "            [Content of the \"Present Illness\" field from '입원초진']\n",
    "    \n",
    "    Guidelines:\n",
    "    - **Admission Date**: Use the date that appears immediately after '>>>입원초진<<<'.\n",
    "    - **Operation Date**: Use the date that appears immediately after '>>>입원경과<<<'.\n",
    "    - **Description**: Use the content from the \"Present Illness\" field in the '입원초진' section. **If the \"Present Illness\" field is brief or lacks detail, include additional relevant information from the '입원초진' and '입원경과' section to provide a complete summary.**\n",
    "    - **Format**: Follow the format and style provided above exactly, including indentation and line breaks.\n",
    "    - **Content**: Use only the information explicitly included in the provided patient data. Do not include interpretations, assumptions, or additional information not present in the data.\n",
    "    - **Consistency**: Apply this format consistently across various cases and adjust the output according to the provided data.\n",
    "    - **Prevent Hallucinations**: Do not include information that is not present in the data. Only extract and present the information provided.\n",
    "    \n",
    "    Generate the output according to the above guidelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt}\n",
    "    ]\n",
    "\n",
    "def generate_discharge_summary(model: Any, processor: Any, admission_notes: str) -> str:\n",
    "    \"\"\"\n",
    "    Generates discharge summary using the LLM model.\n",
    "    \n",
    "    Args:\n",
    "        model: The LLM model\n",
    "        processor: Text processor for the model\n",
    "        admission_notes: Patient's admission and progress notes\n",
    "        \n",
    "    Returns:\n",
    "        Generated discharge summary text\n",
    "    \"\"\"\n",
    "    messages = create_llm_prompt(admission_notes)\n",
    "    \n",
    "    model_input = processor.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    encoded_input = processor(\n",
    "        text=model_input,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    generated_output = model.generate(\n",
    "        **encoded_input, \n",
    "        max_new_tokens=800\n",
    "    )\n",
    "    \n",
    "    full_text = processor.decode(\n",
    "        generated_output[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return extract_discharge_summary_sections(full_text)\n",
    "\n",
    "def process_patient_discharge_summaries(\n",
    "    model: Any,\n",
    "    processor: Any,\n",
    "    patient_records: Dict[str, Dict[str, str]]\n",
    ") -> Tuple[List[str], List[str]]:\n",
    "    \"\"\"\n",
    "    Processes discharge summaries for multiple patients.\n",
    "    \n",
    "    Args:\n",
    "        model: The LLM model\n",
    "        processor: Text processor for the model\n",
    "        patient_records: Dictionary containing patient records\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing lists of generated summaries and actual summaries\n",
    "    \"\"\"\n",
    "    generated_summaries = []\n",
    "    actual_summaries = []\n",
    "    \n",
    "    for index, (patient_id, records) in enumerate(patient_records.items()):\n",
    "        print(f\"Processing Patient #{index} =======\")\n",
    "        \n",
    "        combined_notes = f\"{records['Admission_Note']}\\n{records['Progress_Notes']}\"\n",
    "        cleaned_notes = combined_notes.replace(r'_x000D_\\n', '')\n",
    "        \n",
    "        generated_summary = generate_discharge_summary(\n",
    "            model=model,\n",
    "            processor=processor,\n",
    "            admission_notes=cleaned_notes\n",
    "        )\n",
    "        \n",
    "        generated_summaries.append(generated_summary)\n",
    "        actual_summaries.append(records['Discharge_Summary'])\n",
    "        \n",
    "        print(generated_summary)\n",
    "    \n",
    "    return generated_summaries, actual_summaries\n",
    "\n",
    "def translate_summary(model: Any, processor: Any, summary: str) -> str:\n",
    "    \"\"\"\n",
    "    Translates the given Korean summary into English while maintaining the format.\n",
    "    \n",
    "    Args:\n",
    "        model: The LLM model\n",
    "        processor: Text processor for the model\n",
    "        summary: The Korean summary text to translate\n",
    "        \n",
    "    Returns:\n",
    "        Translated summary text in English\n",
    "    \"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a professional medical translator. Translate the following Korean medical summary into English, maintaining the exact format, indentation, and line breaks. Do not add or omit any information.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": summary\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    model_input = processor.apply_chat_template(\n",
    "        messages, \n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    encoded_input = processor(\n",
    "        text=model_input,\n",
    "        add_special_tokens=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "    \n",
    "    generated_output = model.generate(\n",
    "        **encoded_input, \n",
    "        max_new_tokens=800\n",
    "    )\n",
    "    \n",
    "    translated_summary = processor.decode(\n",
    "        generated_output[0], \n",
    "        skip_special_tokens=True\n",
    "    )\n",
    "    \n",
    "    return translated_summary\n",
    "\n",
    "def translate_summaries(\n",
    "    model: Any,\n",
    "    processor: Any,\n",
    "    summaries: List[str]\n",
    ") -> List[str]:\n",
    "    \"\"\"\n",
    "    Translates a list of Korean summaries into English while maintaining their formats.\n",
    "    \n",
    "    Args:\n",
    "        model: The LLM model\n",
    "        processor: Text processor for the model\n",
    "        summaries: List of Korean summaries to translate\n",
    "        \n",
    "    Returns:\n",
    "        List of translated summaries in English\n",
    "    \"\"\"\n",
    "    translated_summaries = []\n",
    "    \n",
    "    for index, summary in enumerate(summaries):\n",
    "        print(f\"Translating Summary #{index} =======\")\n",
    "        \n",
    "        translated_summary = translate_summary(\n",
    "            model=model,\n",
    "            processor=processor,\n",
    "            summary=summary\n",
    "        )\n",
    "\n",
    "        extracted_text = extract_reason_for_hospitalization_summary(translated_summary)\n",
    "        translated_summaries.append(extracted_text)\n",
    "        print(extracted_text)\n",
    "    \n",
    "    return translated_summaries\n",
    "\n",
    "def extract_reason_for_hospitalization_summary(text):\n",
    "    start_section = \"assistant\"\n",
    "    \n",
    "    if start_section in text:\n",
    "        extracted_text = text.split(start_section, 1)[1]\n",
    "        return extracted_text.strip()\n",
    "    else:\n",
    "        return \"Section not found in the text.\"\n",
    "\n",
    "# Main execution\n",
    "generated_summaries, actual_summaries = process_patient_discharge_summaries(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    patient_records=patient_records\n",
    ")\n",
    "\n",
    "translated_summaries = translate_summaries(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    summaries=generated_summaries\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translating an actual Discharge Summary into English\n",
    "discharge_summaries = []\n",
    "\n",
    "for patient_id, records in patient_records.items():\n",
    "    discharge_summary = records['Discharge_Summary'].replace(r'_x000D_\\n', '')\n",
    "    discharge_summaries.append(discharge_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translating Summary #0 =======\n",
      ">>>Discharge Record<<<\n",
      "2023-05-14 00:00:00\n",
      "Admission and Operation History\n",
      "    2023-03 Admission\n",
      "    2023-03 Operation\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        Admitted with a complaint of bilateral hand numbness and was a follow-up patient for CTS (Carpal Tunnel Syndrome) and B/L (Bilateral) (Bland 1/3). As the symptoms did not improve with conservative treatment, the patient was admitted for CTR (Carpal Tunnel Release) and Lt. (Left) surgery.\n",
      "Translating Summary #1 =======\n",
      ">>>Discharge Record<<<\n",
      "2023-05-23 00:00:00\n",
      "Admission History\n",
      "    2023-03 Admitted\n",
      "    2023-03 Operated\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        Admitted with symptoms of bilateral hand numbness and visited for follow-up for CTS (Carpal Tunnel Syndrome) and B/L (bilateral). As conservative treatment did not show improvement,\n",
      "        This time, admitted for CTR (Carpal Tunnel Release) and Rt + A1 pulley release, 3rd finger, Rt.\n",
      "Translating Summary #2 =======\n",
      ">>>Discharge Record<<<\n",
      "2023-06-01 00:00:00\n",
      "Reason for Admission and Past Medical History\n",
      "    Description\n",
      "        Imp>\n",
      "        #1. Trigger finger, 2nd finger, Lt.\n",
      "\n",
      "Admission and Treatment Course\n",
      "    2023-03Adm\n",
      "    2023-03Op\n",
      "Translating Summary #3 =======\n",
      ">>>Discharge Record<<<\n",
      "2023-06-10 00:00:00\n",
      "Admission Reason and Past Medical History\n",
      "    Description\n",
      "        Admitted for Op. DDLT (Dominant Deceased Donor Liver Transplant)\n",
      "        KFRT due to primary oxalosis caused by AGXT mutation\n",
      "        - HD since 2019-07\n",
      "        - HD catheter: 2019-08 Rt IJV (Right Internal Jugular Vein), 2021-09 Rt IJV\n",
      "        - 2019-08 neck USG (Ultrasound) patent both IJV and left SCV (Subclavian Vein)\n",
      "        - TPL plan: Liver → kidney\n",
      "        Size mismatch로 취소되어 퇴원 (Discharged due to size mismatch)\n",
      "\n",
      "Hospital Course\n",
      "    3/4 admitted for op (operation)\n",
      "    size mismatch로 Op. hold (operation held due to size mismatch)\n",
      "    DC (Discharged)\n",
      "Translating Summary #4 =======\n",
      ">>>Discharge Record<<<\n",
      "2023-06-19 00:00:00\n",
      "Admission and Operation History\n",
      "    2023-03 Admission\n",
      "    2023-03 Operation\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        Admitted for A1 pulley release surgery due to triggering of the 3rd finger.\n"
     ]
    }
   ],
   "source": [
    "translated_actual_summaries = translate_summaries(\n",
    "    model=model,\n",
    "    processor=processor,\n",
    "    summaries=discharge_summaries\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare Model Output with Actual Reference Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<Model Output>>>\n",
      "\n",
      "Admission and Discharge Information\n",
      "    Admission Date: 2023-03-03\n",
      "    Discharge Date: 2023-05-09\n",
      "\n",
      "Reason for Hospitalization and Medical History Summary\n",
      "    Description\n",
      "        Admitted with symptoms of bilateral hand numbness and tingling, and was previously followed up by an outpatient doctor for CTS (Carpal Tunnel Syndrome) and B/L (Bilateral) (Bland 1/3). However, the symptoms did not improve with conservative treatment, and this time admitted for CTR (Carpal Tunnel Release) and Lt. (Left) wrist surgery.\n",
      "\n",
      " ========== Comparison between Model Output and Reference Data ========== \n",
      "\n",
      "<<<Reference Data>>>\n",
      "\n",
      ">>>Discharge Record<<<\n",
      "2023-05-14 00:00:00\n",
      "Admission and Operation History\n",
      "    2023-03 Admission\n",
      "    2023-03 Operation\n",
      "\n",
      "Reason for Hospitalization and Past Medical History Summary\n",
      "    Description\n",
      "        Admitted with a complaint of bilateral hand numbness and was a follow-up patient for CTS (Carpal Tunnel Syndrome) and B/L (Bilateral) (Bland 1/3). As the symptoms did not improve with conservative treatment, the patient was admitted for CTR (Carpal Tunnel Release) and Lt. (Left) surgery.\n"
     ]
    }
   ],
   "source": [
    "patient_id = 0\n",
    "\n",
    "print('<<<Model Output>>>\\n')\n",
    "print(translated_summaries[patient_id])\n",
    "translated_actual_summaries\n",
    "print('\\n', '='*10, 'Comparison between Model Output and Reference Data', '='*10, '\\n')\n",
    "\n",
    "print('<<<Reference Data>>>\\n')\n",
    "print(translated_actual_summaries[patient_id])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Summary Quality Evaluation\n",
    "\n",
    "Evaluate the quality of generated summaries using ROUGE-L and METEOR metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-L score: 0.5780\n",
      "Average METEOR score: 0.5237\n"
     ]
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "meteor = evaluate.load('meteor')\n",
    "\n",
    "results = {\n",
    "    'ROUGE-L': [],\n",
    "    'METEOR': []\n",
    "}\n",
    "\n",
    "for pred, ref in zip(translated_summaries, translated_actual_summaries):\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(pred, ref)[0]\n",
    "    results['ROUGE-L'].append(rouge_scores['rouge-l']['f'])\n",
    "    \n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.compute(predictions=[pred], references=[ref])['meteor']\n",
    "    results['METEOR'].append(meteor_score)\n",
    "\n",
    "for metric, scores in results.items():\n",
    "    avg_score = np.mean(scores)\n",
    "    print(f\"Average {metric} score: {avg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average ROUGE-L score: 0.6713\n",
      "Average METEOR score: 0.6990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# When executed in Korean\n",
    "\n",
    "# Extract Relevant Sections for Comparison with Reference Data\n",
    "new_label_list = []\n",
    "for item in actual_summaries:\n",
    "    if len(item) > 0 and isinstance(item[0], str): \n",
    "        new_label_list.append('\\n'.join(item.split('\\n')[2:]))\n",
    "\n",
    "rouge = Rouge()\n",
    "meteor = evaluate.load('meteor')\n",
    "\n",
    "results = {\n",
    "    'ROUGE-L': [],\n",
    "    'METEOR': []\n",
    "}\n",
    "\n",
    "for pred, ref in zip(generated_summaries, new_label_list):\n",
    "    # Calculate ROUGE scores\n",
    "    rouge_scores = rouge.get_scores(pred, ref)[0]\n",
    "    results['ROUGE-L'].append(rouge_scores['rouge-l']['f'])\n",
    "    \n",
    "    # Calculate METEOR score\n",
    "    meteor_score = meteor.compute(predictions=[pred], references=[ref])['meteor']\n",
    "    results['METEOR'].append(meteor_score)\n",
    "\n",
    "for metric, scores in results.items():\n",
    "    avg_score = np.mean(scores)\n",
    "    print(f\"Average {metric} score: {avg_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
